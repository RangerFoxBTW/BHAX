<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude" version="5.0" xml:lang="hu">
    <info>
        <title>Helló, Calvin!</title>
        <keywordset>
            <keyword/>
        </keywordset>
    </info>
    
    <section>
        <title>MNIST</title>
        <para>
            Az alap feladat megoldása, +saját kézzel rajzolt képet is ismerjen fel,
            <link xlink:href="https://progpater.blog.hu/2016/11/13/hello_samu_a_tensorflow-bol">Tensorflow</link> Háttérként ezt vetítsük le:
            <link xlink:href="https://prezi.com/0u8ncvvoabcr/no-programming-programming/">Prezi</link>"
        </para>
        <para>
            Feladat forrása: <link xlink:href="src/Calvin/mnist.py">mnist.py</link>
        </para>
        <para>
            És végül elérkeztünk a könyv utolsó fejezetéhez…. Ez már érezhetően nehezebb témát dolgoz fel, illetőleg nincs is benne a tantárgyi követelményben az, amit itt számonkérnek… Esetleg az lehetett a célja a Tanár Úrnak ezzel a résszel, hogy kinyissa azokat a bizonyos kapukat a hallgató előtt, és érdeklődni kezdjen a mesterséges intelligencia iránt. Nos, nálam az ellenkezőjét sikerült elérnie. Egyrészt nagyon nehéz a téma, nagyon sok utánajárást igényel, valamint az alapvető tudással sem rendelkezek még, hogy ilyen komplex dolgokat megértsek és leprogramozzak. Szerencsére Bátfai Tanár Úr adott egy kis segítséget a progpater oldalán, illetve a Tensorflow tutoriáljait felhasználva valahogy sikerült abszolválni a feladatokat.
        </para>
        <para>
            Az első feladatunk az volt, hogy a tensorflowos MNIST példát alakítsuk át úgy, hogy a saját kézzel írt számjegyeket is ismerje fel. Mi is az az MNIST? Az MNIST egy adatbázis, ami olyan számjegyekről tartalmaz képeket, amik kézzel íródtak, ezt pedig fel tudjuk használni a programunk betanítására, aminek szintén az lesz a feladata, hogy számokat ismerjen fel. Tulajdonképpen egy neurális hálót hozunk létre, amit a megadott adatbázis segítségével betanítunk számok felismerésére. 
        </para>
        <para>
            Nagyvonalakban egy neurális háló több bemeneti rétegből, több rejtett rétegből és egy kimeneti rétegből épül fel. A bemeneti rétegen keresztül adjuk be neki a felismerni kívánt képet. Minden pixelhez egy-egy bemeneti rétegbeli neuront rendelünk. Ez a réteg valamilyen formájúra alakítja át a képet, majd tovább küldi a rejtett rétegeknek. Itt történik a varázslat, ami alapján előállítja a kimenetet, amit a kimeneti rétegre küld tovább. A különböző bemenetek különböző súlyokkal rendelkeznek, ezek befolyásolják a kimenetet. A hálót be kell tanítanunk, hogy viszonylag magas pontossággal jó eredményt adjon ki végül. Ehhez hatalmas adatbázisra van szükségünk, és még több időre.
        </para>
        <para>
            Ehhez a feladathoz szükségünk lesz néhány előkészületre. Ha Linux alól dolgozunk, akkor érdemes kiadni az alábbi parancsokat:
        </para>
        <para>
            <programlisting language="java"><![CDATA[
$ sudo apt update
$ sudo apt install python3-dev python3-pip
$ sudo apt-get install python3-matplotlib
$ sudo pip3 tensorflow]]></programlisting>
        </para>
        <para>
            Ezután pedig lássuk a példaprogramot:
        </para>
        <para>
            <programlisting language="python"><![CDATA[
# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

# Norbert Batfai, 27 Nov 2016
# Some modifications and additions to the original code:
# https://github.com/tensorflow/tensorflow/blob/r0.11/tensorflow/examples/tutorials/mnist/mnist_softmax.py
# See also http://progpater.blog.hu/2016/11/13/hello_samu_a_tensorflow-bol
# ==============================================================================

"""A very simple MNIST classifier.

See extensive documentation at
http://tensorflow.org/tutorials/mnist/beginners/index.md
"""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse

# Import data
from tensorflow.examples.tutorials.mnist import input_data

import tensorflow as tf

import matplotlib.pyplot


FLAGS = None


def readimg():
    file = tf.read_file("sajat.png")
    img = tf.image.decode_png(file, 1)
    return img

def main(_):
  mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)

  # Create the model
  x = tf.placeholder(tf.float32, [None, 784])
  W = tf.Variable(tf.zeros([784, 10]))
  b = tf.Variable(tf.zeros([10]))
  y = tf.matmul(x, W) + b

  # Define loss and optimizer
  y_ = tf.placeholder(tf.float32, [None, 10])

  # The raw formulation of cross-entropy,
  #
  #   tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)),
  #                                 reduction_indices=[1]))
  #
  # can be numerically unstable.
  #
  # So here we use tf.nn.softmax_cross_entropy_with_logits on the raw
  # outputs of 'y', and then average across the batch.
  cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))
  train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)

  sess = tf.InteractiveSession()
  # Train
  tf.initialize_all_variables().run()
  print("-- A halozat tanitasa")  
  for i in range(1000):
    batch_xs, batch_ys = mnist.train.next_batch(100)
    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
    if i % 100 == 0:
      print(i/10, "%")
  print("----------------------------------------------------------")

  # Test trained model
  print("-- A halozat tesztelese")  
  correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))  
  print("-- Pontossag: ", sess.run(accuracy, feed_dict={x: mnist.test.images,
                                      y_: mnist.test.labels}))
  print("----------------------------------------------------------")
  
  print("-- A MNIST 42. tesztkepenek felismerese, mutatom a szamot, a tovabblepeshez csukd be az ablakat")
  
  img = mnist.test.images[42]
  image = img

  matplotlib.pyplot.imshow(image.reshape(28, 28), cmap=matplotlib.pyplot.cm.binary)
  matplotlib.pyplot.savefig("4.png")  
  matplotlib.pyplot.show()

  classification = sess.run(tf.argmax(y, 1), feed_dict={x: [image]})

  print("-- Ezt a halozat ennek ismeri fel: ", classification[0])
  print("----------------------------------------------------------")

  print("-- A sajat kezi 4-esem felismerese, mutatom a szamot, a tovabblepeshez csukd be az ablakat")

  img = readimg()
  image = img.eval()
  image = image.reshape(28*28)

  matplotlib.pyplot.imshow(image.reshape(28, 28), cmap=matplotlib.pyplot.cm.binary)
  matplotlib.pyplot.savefig("8.png")  
  matplotlib.pyplot.show()

  classification = sess.run(tf.argmax(y, 1), feed_dict={x: [image]})

  print("-- Ezt a halozat ennek ismeri fel: ", classification[0])
  print("----------------------------------------------------------")

if __name__ == '__main__':
  parser = argparse.ArgumentParser()
  parser.add_argument('--data_dir', type=str, default='/tmp/tensorflow/mnist/input_data',
                      help='Directory for storing input data')
  FLAGS = parser.parse_args()
  tf.app.run()]]></programlisting>
        </para>
        <para>
            Az eredeti kódot ki kellett egészíteni a readimg() metódussal, amiben beolvassuk a fájlt, valamint a decode-dal pedig 1 csatornás színskálára (szürkeskálára) alakítjuk azt. Erre azért van szükség, mert a neurális háló így könnyebben tud dolgozni a képpel. Ezután veszi kezdetét a háló betanítása. Itt található néhány változó (az x egy placeholder, a w tartalmazza a súlyokat, a b pedig eltolási értéket, az y pedig az x és w szorzata, amihez hozzá van adva a b.) Ezeket arra használjuk, hogy gradient algoritmusban való felhasználásával a veszteséget optimalizáljuk. Ezután jön a tényleges tanítás, amit 1000 iterációval végzünk. Láthatóak a W_0 súlyok is, amik meghatározzák, hogy az adott kép mekkora eséllyel ábrázol 0-t. 
        </para>
        <para>
            Ezután teszteljük a programot, először a Tensorflow stock adatbázisából a 42-es képet (ez egy négyest ábrázol) ismertetjük fel vele, majd egy saját kézzel rajzoltat. Ez egy picit trükkös volt, mert valami miatt a papírra kézzel írt, majd beszkennelt számot nem volt hajlandó felismerni, illetve paintben is sokáig kellett küszködni, míg kellő vastagsággal tudtam megfelelő számot rajzolni. Innen is látszik, hogy ez egy nagyon kezdetleges program. Alább látható a kimenet, illetve a szám.
        </para>
        <para>
            <mediaobject>
                <imageobject>
                        <imagedata fileref="img/Calvin/mnist1.png" scale="70"/>
                </imageobject>
            </mediaobject>
        </para>
        <para>
            <mediaobject>
                <imageobject>
                        <imagedata fileref="img/Calvin/sajat.png" scale="70"/>
                </imageobject>
            </mediaobject>
        </para>
    </section>

    <section>
        <title>
            DEEP MNIST
        </title>
        <para>Mint az előző, de a mély változattal. Segítő ábra, vesd össze a forráskóddal a
            <link xlink:href="https://arato.inf.unideb.hu/batfai.norbert/NEMESPOR/DE/denbatfai2.pdf">DEEP MNIST</link> 8. fóliáját!
        </para>
        <para>
            Feladat forrása: <link xlink:href="src/Calvin/deepAF.py">deepAF.py</link>
        </para>
        <para>
            Feladatunk ugyanaz volt, mint az előzőben, viszont itt a deep MNSIT-es példát kellett feldolgozni. Ez annyiban tér el az előzőtől, hogy itt több köztes rétegen megy keresztül az adat, ami mégnagyobb (akár 99%) pontossággal határozza meg a képen szereplő számot. Itt van Bátfai Tanár Úr segítő ábrája:
        </para>
        <para>
            <mediaobject>
                <imageobject>
                        <imagedata fileref="img/Calvin/abra.png" scale="70"/>
                </imageobject>
            </mediaobject>
        </para>
        <para>
            Először is ugyanúgy bele kellett tenni, hogy a saját képünket is be tudja olvasni, itt még sok különbség nincs a két kód között.
        </para>
        <para>
            <programlisting language="python"><![CDATA[
def readimg():
file = tf.read_file("sajat.png")
img = tf.image.decode_png(file, 1)
return img

img = readimg()
image = img.eval()
image = image.reshape(28*28)
matplotlib.pyplot.imshow(image.reshape(28, 28), cmap=matplotlib.pyplot.cm.binary)
matplotlib.pyplot.savefig("sajat4.png")
matplotlib.pyplot.show()
classification = sess.run(tf.argmax(y_conv, 1), feed_dict={x: [image], keep_prob: 1.0})]]></programlisting>
        </para>
        <para>
            Mivel ez deep eljárás, így a modellünk is máshogy épül fel (bonyolultabb). Ezúttal több súlyra és biasra van szükségünk. A bias egy speciális súly, amely a perceptron decision boundary-ját mozgatja ki az origóból. A weight_variable és bias_variable fügvényekkel fogjuk ezeket feltölteni ezekkel a tensorokat.
        </para>
        <para>
            <programlisting language="python"><![CDATA[
def weight_variable(shape):
"""weight_variable generates a weight variable of a given shape."""
initial = tf.truncated_normal(shape, stddev=0.1)
return tf.Variable(initial)

def bias_variable(shape):
"""bias_variable generates a bias variable of a given shape."""
initial = tf.constant(0.1, shape=shape)
return tf.Variable(initial)]]></programlisting>
        </para>
        <para>
            Ezúttal a betanítási időt is meg kellett hosszabbítani, ezúttal 20000 iterációban végezzük el. Ez persze azt is maga után vonzza, hogy meghosszabbodik a futási idő is. Ebben persze közrejátszik az is, hogy az előző feladatban látottnál sokkal bonyolultabb a háló felépítése, többször kell a kalkulált adatot megszűrni, így nyilván a futási idő is kitolódik. A notebookomat közel egy órán keresztül izzasztotta, ami egy jobb benchmarkkal is felérne…
        </para>
        <para>
            <programlisting language="python"><![CDATA[
for i in range(20000):
batch = mnist.train.next_batch(50)
if i % 100 == 0:
train_accuracy = accuracy.eval(feed_dict = {x: batch[0], y_: batch[1], keep_prob: 1.0})
print(’step %d, training accuracy %g’ % (i, train_accuracy))
train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})]]></programlisting>
        </para>
        <para>
            Alább látható a kimenete:
        </para>
        <para>
            <mediaobject>
                <imageobject>
                        <imagedata fileref="img/Calvin/mnist2.png" scale="70"/>
                </imageobject>
            </mediaobject>
        </para>
    </section>

    <section>
        <title>Android telefonra a TF objektum detektálója</title>
        <para>
            Telepítsük fel, próbáljuk ki!
        </para>
        <para>
            Tavaly már foglalkoztunk néhány egyszerű Tensorflowos alkalmazással, most itt van még egy. A Tensorflow GitHubjáról tölthető le 
            az <link xlink:href="https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android#building">alkalmazás</link>, amelynek buildeléséhez szükségünk lesz az Android Studio-ra. Először használtam az IDE-t, nagyon szép és letisztult felülete van. Ahhoz, hogy a telefonunkon ki tudjuk próbálni, engedélyezni kell rajta az USB-Debugging funkciót a fejlesztői lehetőségek között.
        </para>
        <para>
            Lássunk mire jutott néhány – az asztalomon lévő - tárgy detektálása közben:
        </para>
        <para>
            <mediaobject>
                <imageobject>
                        <imagedata fileref="img/Calvin/tf1.jpg" scale="50"/>
                </imageobject>
            </mediaobject>
        </para>
        <para>
            <mediaobject>
                <imageobject>
                        <imagedata fileref="img/Calvin/tf2.jpg" scale="50"/>
                </imageobject>
            </mediaobject>
        </para>
        <para>
            <mediaobject>
                <imageobject>
                        <imagedata fileref="img/Calvin/tf3.jpg" scale="50"/>
                </imageobject>
            </mediaobject>
        </para>
        <para>
            <mediaobject>
                <imageobject>
                        <imagedata fileref="img/Calvin/tf4.jpg" scale="50"/>
                </imageobject>
            </mediaobject>
        </para>
        <para>
            <mediaobject>
                <imageobject>
                        <imagedata fileref="img/Calvin/tf5.jpg" scale="50"/>
                </imageobject>
            </mediaobject>
        </para>
        <para>
            <mediaobject>
                <imageobject>
                        <imagedata fileref="img/Calvin/tf6.jpg" scale="50"/>
                </imageobject>
            </mediaobject>
        </para>
        <para>
            <mediaobject>
                <imageobject>
                        <imagedata fileref="img/Calvin/tf7.jpg" scale="50"/>
                </imageobject>
            </mediaobject>
        </para>
        <para>
            <mediaobject>
                <imageobject>
                        <imagedata fileref="img/Calvin/tf8.jpg" scale="50"/>
                </imageobject>
            </mediaobject>
        </para>
        <para>
            <mediaobject>
                <imageobject>
                        <imagedata fileref="img/Calvin/tf9.jpg" scale="50"/>
                </imageobject>
            </mediaobject>
        </para>
        <para>
            Nos, elég kiábrándító végeredmények születtek… Egyrészt helyes eredményt egyedül a tv távirányítóra adott, illetve a billentyűzet egy részét is felismerte. Ez nyilván betudható a kevés adatmennyiségnek, ami alapján dolgozik a felismerő. Viszont ezekben sem volt biztos a program, legtöbbször 50-60% közti bizonyossággal határozta meg az adott tárgy mivoltát. Mindemellett, ha hozzávesszük azt, hogy a tesztek legnagyobb részében téves megállapítást hozott, csúfosan elbukott a program. 
        </para>
    </section>

    <section>
        <title>Minecraft MALMO-s példa</title>
        <para>
            A https://github.com/Microsoft/malmo felhasználásával egy ágens példa, lásd pl.: <link xlink:href="https://bhaxor.blog.hu/2018/11/29/eddig_csaltunk_de_innentol_mi">https://bhaxor.blog.hu/2018/11/29/eddig_csaltunk_de_innentol_mi</link>
        </para>
        <para>
            Megoldás forrása: <link xlink:href="src/Conway/pipacs.py">pipacs.py</link>
        </para>
        <para>
            <programlisting language="python"><![CDATA[
from __future__ import print_function
# ------------------------------------------------------------------------------------------------
# Copyright (c) 2016 Microsoft Corporation
# 
# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and
# associated documentation files (the "Software"), to deal in the Software without restriction,
# including without limitation the rights to use, copy, modify, merge, publish, distribute,
# sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in all copies or
# substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT
# NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
# DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
# ------------------------------------------------------------------------------------------------

# Tutorial sample #2: Run simple mission using raw XML

# Added modifications by Norbert Bátfai (nb4tf4i) batfai.norbert@inf.unideb.hu, mine.ly/nb4tf4i.1
# 2018.10.18, https://bhaxor.blog.hu/2018/10/18/malmo_minecraft
# 2020.02.02, NB4tf4i's Red Flowers, http://smartcity.inf.unideb.hu/~norbi/NB4tf4iRedFlowerHell
# 2020.03.02, https://github.com/nbatfai/RedFlowerHell
# 2020.03.07, "_smartSteve": nof_turn (number of turns) is replaced by the dict self.collectedFlowers 
# 2020.03.11, "_bu": bottom up, s4v3: https://youtu.be/VP0kfvRYD1Y

from builtins import range
import MalmoPython
import os
import sys
import time
import random
import json
import math

if sys.version_info[0] == 2:
    sys.stdout = os.fdopen(sys.stdout.fileno(), 'w', 0)  # flush print output immediately
else:
    import functools
    print = functools.partial(print, flush=True)

# Create default Malmo objects:

agent_host = MalmoPython.AgentHost()
try:
    agent_host.parse( sys.argv )
except RuntimeError as e:
    print('ERROR:',e)
    print(agent_host.getUsage())
    exit(1)
if agent_host.receivedArgument("help"):
    print(agent_host.getUsage())
    exit(0)

# -- set up the mission -- #
missionXML_file='nb4tf4i_d.xml'
with open(missionXML_file, 'r') as f:
    print("NB4tf4i's Red Flowers (Red Flower Hell) - DEAC-Hackers Battle Royale Arena\n")
    print("NB4tf4i vörös pipacsai (Vörös Pipacs Pokol) - DEAC-Hackers Battle Royale Arena\n")
    print("The aim of this first challenge, called nb4tf4i's red flowers, is to collect as many red flowers as possible before the lava flows down the hillside.\n")
    print("Ennek az első, az nb4tf4i vörös virágai nevű kihívásnak a célja összegyűjteni annyi piros virágot, amennyit csak lehet, mielőtt a láva lefolyik a hegyoldalon.\n")    
    print("Norbert Bátfai, batfai.norbert@inf.unideb.hu, https://arato.inf.unideb.hu/batfai.norbert/\n")
    print("Version history\n", "Code: ", sys.argv[0], ", series 4 v.3, bottom up, max 18 poppies. Norbert Bátfai, nbatfai@gmail.com\n")
    print("Loading mission from %s" % missionXML_file)
    mission_xml = f.read()
    my_mission = MalmoPython.MissionSpec(mission_xml, True)
    my_mission.drawBlock( 0, 0, 0, "lava")

class Hourglass:
    def __init__(self, charSet):
        self.charSet = charSet
        self.index = 0
    def cursor(self):
        self.index=(self.index+1)%len(self.charSet)
        return self.charSet[self.index]

hg = Hourglass('|/-\|')

class Steve:
    def __init__(self, agent_host):
        self.agent_host = agent_host
        
        self.x = 0
        self.y = 0
        self.z = 0
        self.yaw = 0
        self.pitch = 0
        
        self.front_of_me_idx = 0
        self.front_of_me_idxr = 0
        self.front_of_me_idxl = 0        
        self.right_of_me_idx = 0
        self.left_of_me_idx = 0        
        
        self.nof_red_flower = 0
        self.lookingat = ""
        self.attackLvl = 0
        
        self.collectedFlowers = {}
        for i in range(100):
            self.collectedFlowers[i] = False

        self.collectedFlowers[1] = True
        self.collectedFlowers[2] = True

    def checkInventory(self, observations):
        for i in range(2):
            hotbari = 'Hotbar_'+str(i)+'_item'
            hotbars = 'Hotbar_'+str(i)+'_size'
            slot0_contents = observations.get(hotbari, "")
            if slot0_contents == "red_flower":
                slot0_size = observations.get(hotbars, "")
                if self.nof_red_flower < slot0_size :
                    self.nof_red_flower = slot0_size                                            
                    print("            A RED FLOWER IS MINED AND PICKED UP")
                    print("            Steve's lvl: ", self.y, "Flower lvl: ", self.attackLvl) 
                    self.collectedFlowers[self.attackLvl] = True
                    self.agent_host.sendCommand( "look -1" )
                    time.sleep(.4)
                    if self.lvlUp(observations.get("nbr3x3", 0)):
                        return True
    def pickUp(self):
        self.agent_host.sendCommand( "attack 1" )
        time.sleep(.23)
        self.attackLvl = self.y

    def lvlUp(self, nbr):
        if self.collectedFlowers[self.y]:
            self.turnToWall(nbr)
            self.agent_host.sendCommand( "jumpmove 1" )
            time.sleep(.2)                
            self.agent_host.sendCommand( "jumpmove 1" )
            time.sleep(.2)
            return True
        else:
            return False

    def idle(self, delay):
        #print("      SLEEPING for ", delay)
        time.sleep(delay)
                                                        
    def isInTrap(self, nbr):
            
        dc = 0    
        nbri = [9,10,11,12,14,15,16,17]    
        for i in range(1, len(nbri)):
            if nbr[nbri[i]]=="dirt" :
                dc = dc + 1            
        return dc > 5
    
    def turnFromWall(self, nbr):
        if (nbr[self.right_of_me_idx+9]=="air" and nbr[self.left_of_me_idx+9]=="dirt") or (nbr[self.right_of_me_idx]=="air" and nbr[self.left_of_me_idx]=="dirt"):
            self.agent_host.sendCommand( "turn 1" )
        else:
            self.agent_host.sendCommand( "turn -1" )
        time.sleep(.2)

    def turnToWall(self, nbr):
        if (nbr[self.right_of_me_idx+9]=="air" and nbr[self.left_of_me_idx+9]=="dirt") or (nbr[self.right_of_me_idx]=="air" and nbr[self.left_of_me_idx]=="dirt"):
            self.agent_host.sendCommand( "turn -1" )
        else:
            self.agent_host.sendCommand( "turn 1" )
        time.sleep(.2)

    def calcNbrIndex(self):
        if self.yaw >= 180-22.5 and self.yaw <= 180+22.5 :
            self.front_of_me_idx = 1
            self.front_of_me_idxr = 2
            self.front_of_me_idxl = 0
            self.right_of_me_idx = 5
            self.left_of_me_idx = 3            
        elif self.yaw >= 180+22.5 and self.yaw <= 270-22.5 :
            self.front_of_me_idx = 2 
            self.front_of_me_idxr = 5
            self.front_of_me_idxl =1             
            self.right_of_me_idx = 8
            self.left_of_me_idx = 0            
        elif self.yaw >= 270-22.5 and self.yaw <= 270+22.5 :
            self.front_of_me_idx = 5
            self.front_of_me_idxr = 8
            self.front_of_me_idxl = 2
            self.right_of_me_idx = 7
            self.left_of_me_idx = 1                        
        elif self.yaw >= 270+22.5 and self.yaw <= 360-22.5 :
            self.front_of_me_idx = 8            
            self.front_of_me_idxr = 7
            self.front_of_me_idxl = 5          
            self.right_of_me_idx = 6
            self.left_of_me_idx = 2                        
        elif self.yaw >= 360-22.5 or self.yaw <= 0+22.5 :
            self.front_of_me_idx = 7
            self.front_of_me_idxr = 6
            self.front_of_me_idxl = 8
            self.right_of_me_idx = 3
            self.left_of_me_idx = 5                        
        elif self.yaw >= 0+22.5 and self.yaw <= 90-22.5 :
            self.front_of_me_idx = 6
            self.front_of_me_idxr = 3
            self.front_of_me_idxl = 7          
            self.right_of_me_idx = 0
            self.left_of_me_idx = 8                        
        elif self.yaw >= 90-22.5 and self.yaw <= 90+22.5 :
            self.front_of_me_idx = 3
            self.front_of_me_idxr = 0
            self.front_of_me_idxl = 6
            self.right_of_me_idx = 1
            self.left_of_me_idx = 7                        
        elif self.yaw >= 90+22.5 and self.yaw <= 180-22.5 :
            self.front_of_me_idx = 0
            self.front_of_me_idxr = 1
            self.front_of_me_idxl = 3
            self.right_of_me_idx = 2
            self.left_of_me_idx = 6                        
        else:
            print("There is great disturbance in the Force...")            

    def whatISee(self, observations):
        self.lookingat = "NOTHING"            
        if "LineOfSight" in observations:
            lineOfSight = observations["LineOfSight"] 
            self.lookingat = lineOfSight["type"]      

    def whatMyPos(self, observations):
        if "Yaw" in observations:
            self.yaw = int(observations["Yaw"])
        if "Pitch" in observations:
            self.pitch = int(observations["Pitch"])
        if "XPos" in observations:
            self.x = int(observations["XPos"])
        if "ZPos" in observations:
            self.z = int(observations["ZPos"])        
        if "YPos" in observations:
            self.y = int(observations["YPos"])        
            
    def run(self):
        world_state = self.agent_host.getWorldState()
        # Loop until mission ends:
        while world_state.is_mission_running:
            
            #print(">>> nb4tf4i arena -----------------------------------\n")
            act = self.action(world_state)
            #print("nb4tf4i arena >>> -----------------------------------\n")
            if not act:
                self.idle(.017)
            world_state = self.agent_host.getWorldState()

    def action(self, world_state):
        for error in world_state.errors:
            print("Error:", error.text)
        
        if world_state.number_of_observations_since_last_state == 0:
            #print("    NO OBSERVATIONS NO ACTIONS")
            return False
        
        input = world_state.observations[-1].text
        observations = json.loads(input)
        nbr = observations.get("nbr3x3", 0)
        #print(observations)
        
        self.whatMyPos(observations)
        print("\r    Steve's Coords: ", self.x, self.y, self.z, end='')        
        #print("    Steve's Yaw: ", self.yaw)        
        #print("    Steve's Pitch: ", self.pitch)        

        self.checkInventory(observations)
        #print("Number of flowers: ", self.nof_red_flower)

        self.whatISee(observations)
        #print("    Steve's <): ", self.lookingat)
                        
        self.calcNbrIndex()                
                        
        if self.isInTrap(nbr) :
            self.agent_host.sendCommand( "jumpmove 1" )
            time.sleep(.1)
            self.turnFromWall(nbr)
            self.agent_host.sendCommand( "jumpmove 1" )
            time.sleep(.1)            
            return True

        if self.lookingat == "red_flower":
            print(" A RED FLOWER IS FOUND (lookingat)")
            self.pickUp()
            return True
        
        for i in range(9):
            if nbr[i]=="red_flower" or nbr[i+9]=="red_flower" or nbr[i+18]=="red_flower":
                print("        I CAN SEE A RED FLOWER: ", i, " LEVEL ", self.y)
                if i == self.front_of_me_idx :
                    print("F            A RED FLOWER IS RIGTH IN FRONT OF ME")
                    self.agent_host.sendCommand( "move 1" )
                    time.sleep(.2)
                    self.agent_host.sendCommand( "look 1" )
                    time.sleep(.2)
                    print("Steve <) ", self.lookingat)
                    return True
                elif i == self.front_of_me_idxr :
                    print("R            A RED FLOWER IS RIGTH IN RIGHT OF ME")
                    self.agent_host.sendCommand( "strafe 1" )
                    time.sleep(.2)
                    return True
                elif i == self.front_of_me_idxl :
                    print("L            A RED FLOWER IS RIGTH IN LEFT OF ME")
                    self.agent_host.sendCommand( "strafe -1" )
                    time.sleep(.2)
                    return True
                elif i == 4  :
                    self.red_flower_is_mining = True
                    print("            I AM STANDING ON A RED FLOWER!!!")
                    
                    if self.pitch != 90:
                        self.agent_host.sendCommand( "look 1" )
                        print("PITCH            I AM STANDING ON A RED FLOWER!!!")
                        time.sleep(.3)
                    else:
                        print("ATTACK            I AM STANDING ON A RED FLOWER!!! LEVEL ", self.y)
                        self.pickUp()
                        self.agent_host.sendCommand( "look -1" )
                        time.sleep(.3)
                    return True
                
                else :
                    print("            I AM TURNING TO A RED FLOWER")
                    self.agent_host.sendCommand( "turn 1" )
                    time.sleep(.2)
                    return True
  
        if self.lvlUp(nbr):
            print("        LVL UP")

        if nbr[self.front_of_me_idx+9]!="air" and nbr[self.front_of_me_idx+9]!="red_flower":
            print("        THERE ARE OBSTACLES IN FRONT OF ME ",  nbr[self.front_of_me_idx], end='')
  
            self.turnFromWall(nbr)
                        
        else:
            print("        THERE IS NO OBSTACLE IN FRONT OF ME", end='')
            
            if nbr[self.front_of_me_idx]=="dirt":
                self.agent_host.sendCommand( "move 1" )
                time.sleep(.013)
            else:
                self.turnFromWall(nbr)                
                
        return True        

num_repeats = 1
for ii in range(num_repeats):

    my_mission_record = MalmoPython.MissionRecordSpec()

    # Attempt to start a mission:
    max_retries = 6
    for retry in range(max_retries):
        try:
            agent_host.startMission( my_mission, my_mission_record )
            break
        except RuntimeError as e:
            if retry == max_retries - 1:
                print("Error starting mission:", e)
                exit(1)
            else:
                print("Attempting to start the mission:")
                time.sleep(2)

    # Loop until mission starts:
    print("   Waiting for the mission to start")
    world_state = agent_host.getWorldState()

    while not world_state.has_mission_begun:
        print("\r"+hg.cursor(), end="")
        time.sleep(0.15)
        world_state = agent_host.getWorldState()
        for error in world_state.errors:
            print("Error:",error.text)

    print("NB4tf4i Red Flower Hell running\n")
    steve = Steve(agent_host)
    steve.run()
    print("Number of flowers: "+ str(steve.nof_red_flower))
    time.sleep(3)

print("Mission ended")
# Mission has ended.]]></programlisting>
        </para>
        <para>
            Az ágens felfelé halad csigamozgásban, diszkrét utasításokkal az arénában, és az érzékelt pipacsokat felszedi. Ideális esetben 19-et szed fel (nekem 16-nál nem tudott többet). 
            A végén kiírja az összeszedett virágok összegét.
        </para>
        <para>
            Létrehozunk egy Steve osztályt, majd definiáljuk azt: x,y,z koordináták, amik a világ koordinátái, a yaw-t, ami az érzékeléshez kell (ObservationFromGrid), valamint a pitch-et, 
            ami a fel-le nézéshez kell. Az utána következő adattagok a Steve körüli kockákat jelöli.  Ezután még definiáljuk a virágok számát, hogy mire néz, és az attacklvl-t. Ezek 
            értékét 0-ra állítjuk. Ezután tudatjuk az ágenssel, hogy hány virágot szedett eddig össze. A checkInventory-val az inventoryját tudja ellenőrizni: ha bekerül egy virág, akkor 
            azt kiírja, illetve ezzel követi nyomon, hogy melyik szinten szedte már össze a virágot. A pickUp segítségével szedi fel a virágot, az attack paranccsal. 
        </para>
        <para>
            A lvlUp-pal lép szintet, ezt, mindig akkor teszi, ha kiütötte és felvette a jelenlegi szinten lévő pipacsot. Ugrani a jumpmove paranccsal tud. Az isInTrap vizsgálja, hogy 
            belement-e valami csapdába Steve, pl. ha kiütötte maga alatt a földet, és nem tud simán továbbmenni (vagyis ha föld kockák fogják közre őt). Ezután következnek a fordulási 
            parancsok. A calcNbrIndex számolja a körülötte érzékelt kockákat (a tájékozódáshoz kell). A whatISee kiírja a terminálra, hogy mit érzékel maga körül. A whatMyPos lekérdezi a 
            saját pozícióját. (Elég beszédesek ezek a nevek, feleslegesnek érzem túlmagyarázni őket.)
        </para>
        <para>
            A def run(self) a lényegi része, ez hívódik meg a program indításakor. Steve megkapja az érzeteket, majd egy ciklus fut addig, amíg véget nem ér a küldetés (ha meghal, vagy 
            letelik a számláló). Ezután megnézi, hogy csapdában van-e, ha igen, akkor kiugrik onnan. Ha lát egy pipacsot, akkor kiírja a terminálra,  lenéz rá, és kiüti azt.  A for 
            ciklussal vizsgálja, hogy merre vannak virágok, ha érzékel egyet, akkor azt kiírja, ha rajta áll, akkor kiüti. Ezután szintet lép. Ha nem sikerül neki, akkor kiírja, hogy 
            akadályba ütközött, és próbál elfordulni. Ha nincs előtte akadály, akkor előre mozog tovább. 
        </para>
    </section>
    
</chapter>                
